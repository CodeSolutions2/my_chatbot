<!DOCTYPE html>
<html>
<head></head>
<body>    


<h1>Mychatbot webapp</h1>

<!-- ---------------------------------------- -->
<!-- View two split window -->
<div align="left">
<table style='text-align: left; width: 500px; display:block'>
<tr>

<th id="inputs">

<h1></h1>

<h3>[Step 2] View notification and errors about chatbot creation.</h3>
<div id="notification"></div>
<div id="error"></div>
<div id="response"></div>
<div id="output_FILE_ID"></div>
<div id="output_ASSISTANT_ID"></div>
<div id="output_THREAD_ID"></div>
<div id="output_THREAD_MESSAGE_ID"></div>
<div id="output_RUN_ID"></div>
<br>

</th>

<!-- ---------------------------------------- -->
<th id="outputs">
<h3 id="qa_ask_chatbot_h3" style="display:block">[Step 4] Ask the chatbot questions.</h3>
<!-- ---------------------------------------- -->
<!-- View chatbot -->
<input id="prompt" type="text" value="" placeholder="Ask the chatbot questions about the text/file" rows="10" cols="100" style="display:block; text-align: left; height: 50px; width:600px;"><button id="run_selection" onclick="run_selection()">Run Selection</button>
<table id="chatbot_output" style='text-align: left; width: 300px; display:none'>
<!-- dynamically add rows here -->
</table>
<!-- ---------------------------------------- -->
</th>

</tr>
</table>
</div>  
<!-- ---------------------------------------- -->

<!-- ---------------------------------------- -->
<!-- CSS -->
<style>
div { padding: 10px; display:block; font-family:courier; font-size:15px; height:10px; }
	
div#notification { position: relative; color: #3236a8; }
div#error { position: relative; color: #bd1f17; }

div#response { display:none; color: #3236a8; }
div#output_FILE_ID { display:none; }
div#output_ASSISTANT_ID { display:none; }
div#output_THREAD_ID { display:none; }
div#output_THREAD_MESSAGE_ID { display:none; }
div#output_RUN_ID { display:none; }

table {vertical-align: top; border-collapse: collapse; position: relative; z-index: 0; border: 0px solid black;}

tr {vertical-align: top; border: 0px solid black; padding: 10px 20px; }

th, td {vertical-align: top; border: 0px solid black; padding: 10px 20px; }

input#prompt {background-color: #acbdac; border: 0.5px grey; -webkit-border-radius: 5px;-moz-border-radius: 5px;border-radius: 5px;}
</style>


<!-- --------------------------------------------------- -->	  

	  
<script>



// ----------------------------------------------------


async function run_selection() {
  
  var chatbot_method = 'openai_assistant'; // 'openai_q_and_a_finetuning', 'openai_q_and_a_finetuning_vec_sim', 'custom_model'
  
    if (chatbot_method == 'openai_assistant') {

		// ----------------------------------------
		// Define the instructions
		// ----------------------------------------
		// Step B
		create_an_assistant_assistant_name = "give a response using file";
		
		create_an_assistant_description = "You are a helpful document content reading and analyzing assistant that responds to content in a file.";
		
		create_an_assistant_instructions = "You are a helpful document content reading and analyzing assistant that responds to content in a file concisely, using the least number of words. Read the content of a file and respond to the following question: "+document.getElementById("prompt").value+".";
			
		// Step C
		create_a_thread_content = "Read the content of a file and respond to the following request: "+document.getElementById("prompt").value+". Format the output concisely with only the response, use the least number of words.";
			
		// Step D
		add_a_message_to_a_thread_content = "Read the content of a file respond to the following request: "+document.getElementById("prompt").value+". Format the output concisely with only the response, use the least number of words.";
		// ----------------------------------------
			await run_stepsD_to_G_OpenAI_assistant();
		
		
	} else if (chatbot_method == 'openai_q_and_a_finetuning') {
		document.getElementById('error').innerHTML = "Not yet organized: in progress";
		// await run_all_steps_OpenAI_QandA_finetuning();
		
	} else if (chatbot_method == 'openai_q_and_a_finetuning_vec_sim') {
		document.getElementById('error').innerHTML = "Not yet organized: in progress";
		// await run_all_steps_OpenAI_QandA_finetuning_vector_sim();
		
	} else {
    // custom trained model
		document.getElementById('error').innerHTML = "Custom model in progress";
      } 
}

async function run_stepsC_to_G_OpenAI_assistant() {
	
	// Step D
	add_a_message_to_a_thread_content = "Read the content of a file respond to the following request: "+document.getElementById("prompt").value+". Format the output concisely with only the response, use the least number of words.";

  // Step C: outputs THREAD_ID
	await create_a_thread()
		// Step D: outputs THREAD_MESSAGE_ID
		.then(async function() { await add_a_message_to_a_thread(); })
		// Step E: outputs RUN_ID
		.then(async function() {  await run_the_assistant(); })
		// Step F: wait for run to finish
		.then(async function() { await wait_for_run_to_finish(); })
		// Step G
		.then(async function() { await display_the_assistants_response(); })
		.catch(error => { document.getElementById('error').innerHTML = error; });
}


// ----------------------------------------------------

// Step C
async function create_a_thread() {
		
		const url = "https://api.openai.com/v1/threads";
		var headers = {"Content-Type": "application/json", 
			       "Authorization": 'Bearer ' + document.getElementById("OPENAI_API_KEY").value, 
			       "OpenAI-Beta": 'assistants=v2'}
	
	
		// File search enables the assistant with knowledge from files that you or your users upload. Once a file is uploaded, the assistant automatically decides when to retrieve content based on user requests.
		
		// Code Interpreter enables the assistant to write and run code. This tool can process files with diverse data and formatting, and generate files such as graphs.
		
		// Instructions on https://platform.openai.com/docs/assistants/how-it-works/managing-threads-and-messages?lang=python
		var messages = [{"role": "user", "content": create_a_thread_content, "attachments": [{"file_id": document.getElementById('output_FILE_ID').innerHTML, "tools": [{"type": "code_interpreter"}]}]}];
		
		var data = {"messages": messages};
		
		var options = {method : 'POST', headers: headers, body : JSON.stringify(data)};
	
		await fetch(url, options)
		 	.then(response => response.json())
		 	.then(async function(result) {
				let output = JSON.parse(JSON.stringify(result));
				document.getElementById('output_THREAD_ID').innerHTML = output['id'];
			})
			.then(async function() { document.getElementById('notification').innerHTML = "STEP C create_a_thread finished." })
		 	.catch(error => { document.getElementById('error').innerHTML = error; });
	
	
}
	
// ----------------------------------------------------

// Step D
async function add_a_message_to_a_thread() {
	
	const url = "https://api.openai.com/v1/threads/"+document.getElementById('output_THREAD_ID').innerHTML+"/messages";
	var headers = {"Content-Type": "application/json", 
		       "Authorization": 'Bearer ' + document.getElementById("OPENAI_API_KEY").value, 
		       "OpenAI-Beta": 'assistants=v2'};
	
	var data = {"role": "user", "content": add_a_message_to_a_thread_content};
	var options = {method : 'post', headers: headers, body : JSON.stringify(data)};

	await fetch(url, options)
	 	.then(response => response.json())
	 	.then(async function(result) {
			let output = JSON.parse(JSON.stringify(result));
			document.getElementById('output_THREAD_MESSAGE_ID').innerHTML = output['id'];
		})
		.then(async function() { document.getElementById('notification').innerHTML = "STEP D add_a_message_to_a_thread finished." })
	 	.catch(error => { document.getElementById('error').innerHTML = error; });
}

  
// ----------------------------------------------------

  
// Step E
async function run_the_assistant() {
	
	// Create a run such that the assistant reads the thread and decides whether to call tools or use a model to respond to the query.
	// https://platform.openai.com/docs/api-reference/runs/createRun
	
	const url = "https://api.openai.com/v1/threads/"+document.getElementById('output_THREAD_ID').innerHTML+"/runs";
	var headers = {"Content-Type": "application/json", 
		       "Authorization": 'Bearer ' + document.getElementById("OPENAI_API_KEY").value, 
		       "OpenAI-Beta": 'assistants=v2'};

	// ---------------------------
	// Run original Assistant instructions
	// ---------------------------
	var data = {"assistant_id": document.getElementById('output_ASSISTANT_ID').innerHTML};
	
	var options = {method : 'POST', headers: headers, body : JSON.stringify(data)};
	
	await fetch(url, options)
	 	.then(response => response.json())
	 	.then(async function(result) {
			let output = JSON.parse(JSON.stringify(result));
			document.getElementById('output_RUN_ID').innerHTML = output['id'];
		})
		.then(async function() { document.getElementById('notification').innerHTML = "STEP E run_the_assistant finished." })
	 	.catch(error => { document.getElementById('error').innerHTML = error; });
	
}


// ----------------------------------------------------
  
// Step F
async function check_the_run_status() {

	// https://platform.openai.com/docs/api-reference/runs/getRun
	
	const url = "https://api.openai.com/v1/threads/"+document.getElementById('output_THREAD_ID').innerHTML+"/runs/"+document.getElementById('output_RUN_ID').innerHTML;
	var headers = {"Authorization": 'Bearer ' + document.getElementById("OPENAI_API_KEY").value, 
		       "OpenAI-Beta": 'assistants=v2'};
	var options = {method : 'GET', headers: headers};
	
	return await fetch(url, options)
	 	.then(response => response.json())
	 	.then(async function(result) { return JSON.parse(JSON.stringify(result)); })
	 	.catch(error => { document.getElementById('error').innerHTML = error; });

}


async function wait_for_run_to_finish() {

	document.getElementById('notification').innerHTML = "STEP F wait_for_run_to_finish Processing..."
	
	let flag = 'wait_for_completion';
	let c = 0;
	let max_allowed_loops = 30;

	await check_the_run_status()
		.then(async function(out) {  await new Promise(r => setTimeout(r, 5000)); return out; })
		.then(async function(out) {
			var run_status = out;
				
			while (flag == 'wait_for_completion') {
				if ((run_status.status == "queued" || run_status.status == "in_progress" || run_status.status == "completed") & c < max_allowed_loops) {
					// wait a bit, call run status again
					run_status = await check_the_run_status()
						.then(async function(out) { await new Promise(r => setTimeout(r, 5000)); return out; })
						.then(async function(run_status) {
							if (run_status.status == "completed") { flag = "stop loop"; }; 
							return run_status; 
						});
			
				} else {
					flag = "stop loop";
				}
				// console.log(' c: ', c);
				c = c + 1;
			}
			// console.log(' FINAL: ', run_status.status);
		})
		.then(async function() { document.getElementById('notification').innerHTML = "STEP F wait_for_run_to_finish finished." })
		.catch(error => { document.getElementById('error').innerHTML = error; });
}
  
// ----------------------------------------------------
  
// Step G
async function display_the_assistants_response() {
	
	// https://platform.openai.com/docs/api-reference/messages/listMessages?lang=curl
	// List messages: GET https://api.openai.com/v1/threads/{thread_id}/messages
	
	const url = "https://api.openai.com/v1/threads/"+document.getElementById('output_THREAD_ID').innerHTML+"/messages";
	var headers = {"Content-Type": "application/json", 
		       "Authorization": 'Bearer ' + document.getElementById("OPENAI_API_KEY").value, 
		       "OpenAI-Beta": 'assistants=v2'};
	var options = {method : 'GET', headers: headers};
  
	await fetch(url, options)
	 	.then(response => response.json())
	 	.then(async function(result) {
			let output = JSON.parse(JSON.stringify(result));
			
			document.getElementById('response').innerHTML = "Assistant Response:";
			document.getElementById('response').innerHTML += "\n\n";
			output['data'].forEach(async function(row, index){
				let text_output = output['data'][index]['content'][0]['text']['value'];
				if (index == 0) {
					document.getElementById('response').innerHTML += text_output;
					await print_response_to_frontend();
				}
			});
			
		})
		.then(async function() { 
			document.getElementById('notification').innerHTML = "STEP G display_the_assistants_response finished."; 
		})
	 	.catch(error => { document.getElementById('error').innerHTML = error; });

}

	
// ----------------------------------------------------


async function print_response_to_frontend() {

	document.getElementById("chatbot_output").style.display = "block";
	
	// Print response to Frontend here
	let tbl = document.getElementById("chatbot_output");
	let tblBody = document.createElement("tbody");
	
	// Add to Frontend: Create a cellText OR textarea
	let row = document.createElement("tr");
	let cell = document.createElement("td");
	cell.style.backgroundColor = "#cacccf";
	let cellText = document.createTextNode(`User: ${document.getElementById("prompt").value}`);
	cell.appendChild(cellText);
	cell.style.border = "10px solid rgba(0, 0, 0, 0)";
	row.appendChild(cell);
	tblBody.appendChild(row);
	tbl.appendChild(tblBody);
	
	// Add chatbot output to Frontend: Create a cellText OR textarea
	row = document.createElement("tr");
	cell = document.createElement("td");
	cell.style.backgroundColor = "#dbc49e";
	cellText = document.createTextNode(`Chatbot: ${document.getElementById('response').innerHTML}`);
	cell.appendChild(cellText);
	cell.style.border = "10px solid rgba(0, 0, 0, 0)";
	row.appendChild(cell);
	tblBody.appendChild(row);
	tbl.appendChild(tblBody);
	
}
	
// ----------------------------------------------------



// ----------------------------------------------------


// ----------------------------------------------------

// ----------------------------------------------------

// ----------------------------------------------------

// ----------------------------------------------------
</script>

  </body>
</html>
